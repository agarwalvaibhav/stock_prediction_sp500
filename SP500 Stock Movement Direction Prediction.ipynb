{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import time\n",
    "import re\n",
    "from operator import itemgetter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from tsfresh import extract_features, select_features\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing \n",
    "transform raw data into daily return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_null_rows(df, colname_list):\n",
    "    for colname in colname_list:\n",
    "        try:\n",
    "            df = df[df[colname]!=\"null\"].copy()\n",
    "        except:\n",
    "            pass\n",
    "    return df\n",
    "\n",
    "def drop_zero_rows(df, colname_list):\n",
    "    for colname in colname_list:\n",
    "        df = df[df[colname]!=0].copy()\n",
    "    return df\n",
    "\n",
    "def get_close_close_data(path, min_sample, min_start_date):\n",
    "    df_list = []\n",
    "    for fname in os.listdir(path):\n",
    "        df = pd.read_csv(os.path.join(path, fname), sep = \",\")     \n",
    "        nb_rows = df.shape[0]\n",
    "    \n",
    "        # drop rows where \"null\" is appeared\n",
    "        df = drop_null_rows(df, [\"Close\", 'Open'])\n",
    "        dropped_null_rows = df.shape[0] - nb_rows\n",
    "        if dropped_null_rows > 0:\n",
    "            print(\"Dropped null rows at {}: {:d}\".format(fname, dropped_null_rows))\n",
    "\n",
    "        # only keep files where:\n",
    "        # - sample size > min_sample\n",
    "        # - first active date < min_start_date\n",
    "        if df.shape[0] > min_sample and df['Date'][0] <= min_start_date:\n",
    "            colname = fname.split(\".\")[0]\n",
    "            df[colname] = np.log(df['Close'].astype(float)/df['Close'].shift().astype(float))\n",
    "            df = df[['Date', colname]].copy()\n",
    "            df.set_index(\"Date\", inplace = True)\n",
    "            df_list.append(df)\n",
    "    return df_list\n",
    "\n",
    "def main_load_close_close(from_path, to_path, to_name, min_sample = 2000, min_start_date = \"2009-01-01\"):\n",
    "    df_list = get_close_close_data(path = from_path, min_sample = min_sample, min_start_date = min_start_date)\n",
    "    df_all = pd.concat(df_list, axis = 1)\n",
    "    \n",
    "    df_all = df_all.fillna(method='ffill')\n",
    "    df_all = df_all.loc[df_all.index >= min_start_date]\n",
    "    \n",
    "    df_all.to_csv(os.path.join(to_path, to_name), sep = \";\", header = True, index = True)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jiaoy\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\core\\ops.py:714: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = getattr(x, name)(y)\n"
     ]
    }
   ],
   "source": [
    "stock_return_df = main_load_close_close(from_path = \"shared_data/stocks\", to_path = \"shared_data\", to_name = \"sp_close_close_return.csv\")\n",
    "index_return_df = main_load_close_close(from_path = \"shared_data/index\", to_path = \"shared_data\", to_name = \"index_close_close_return.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of stocks kept: 463\n",
      "Indexes kept: ['aord', 'dax', 'djia', 'ftse', 'hangseng', 'nikkei', 'nyse', 'snp']\n"
     ]
    }
   ],
   "source": [
    "print(\"Nb of stocks kept: {}\".format(stock_return_df.shape[1]))\n",
    "print(\"Indexes kept: {}\".format(list(index_return_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_one_lag_feature(mydf, colname, lag):\n",
    "    arr = mydf[colname]\n",
    "    feat_name = \"{}_lag_{:d}\".format(colname, lag)\n",
    "    lagged_arr = arr.shift(lag)\n",
    "    return feat_name, lagged_arr\n",
    "\n",
    "def build_lag_features(mydf, stock_name, lag_list = [1, 2, 3, 4, 5], verbose = False):\n",
    "    \"\"\"\n",
    "    Build lag features from given dataframe\n",
    "    \"\"\"\n",
    "    res_df = pd.DataFrame()\n",
    "    for lag in lag_list:\n",
    "        feat_name, lagged_arr = make_one_lag_feature(mydf, stock_name, lag)\n",
    "        res_df[feat_name] = lagged_arr\n",
    "    if verbose:\n",
    "        print(\"Feature set size:\", res_df.shape)\n",
    "    return res_df\n",
    "\n",
    "def main_save_lag_features(mydf, folder_name = \"self_lag_5\", lag_list = [1, 2, 3, 4, 5], verbose = False):\n",
    "    to_dir = os.path.join(\"shared_data\", \"features\", folder_name)\n",
    "    if not os.path.isdir(to_dir):\n",
    "        os.makedirs(to_dir)\n",
    "    for stock_name in mydf.columns:\n",
    "        feat_df = build_lag_features(mydf = mydf, stock_name = stock_name, lag_list = lag_list, verbose = verbose)\n",
    "        feat_df.to_csv(os.path.join(to_dir, \"{}.csv\".format(stock_name)), index = True, header = True, sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_save_lag_features(mydf = index_return_df, folder_name = \"index_lag_5\", lag_list = [1, 2, 3, 4, 5], verbose = False)\n",
    "main_save_lag_features(mydf = stock_return_df, folder_name = \"self_lag_5\", lag_list = [1, 2, 3, 4, 5], verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEAT_DIR = os.path.join(\"shared_data\", \"features\")\n",
    "RES_DIR = os.path.join(\"shared_data\", \"result\")\n",
    "TEST_RES_DIR = os.path.join(RES_DIR, \"testset\")\n",
    "# load the return data of all assets\n",
    "TARGET_DF = pd.read_csv(\"shared_data/sp_close_close_return.csv\", sep = \";\", header = 0, index_col = 0)\n",
    "TARGET_DF_INDEX = pd.read_csv(\"shared_data/index_close_close_return.csv\", sep = \";\", header = 0, index_col = 0)\n",
    "EUR_INDEX = [\"dax\", \"ftse\"]\n",
    "USA_INDEX = [\"djia\", \"nyse\", \"snp\"]\n",
    "ASIA_INDEX = [\"aord\", \"hangseng\", \"nikkei\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_feat_df(feat_df, verbose = True):\n",
    "    \"\"\"\n",
    "    Clena up raw feature df that may contain NA\n",
    "    \"\"\"\n",
    "    tot = feat_df.shape[0]\n",
    "    # drop rows containing na\n",
    "    feat_df.dropna(how = \"any\", inplace = True, axis = 0)\n",
    "    if verbose:\n",
    "        print(\"dropped na rows: \", tot - feat_df.shape[0])\n",
    "    \n",
    "    target = (feat_df['target'].values > 0).astype(int)\n",
    "    feat_df = feat_df.drop(\"target\", axis = 1)\n",
    "    return feat_df, target \n",
    "\n",
    "def load_features(asset_name, feature_name_list, feature_dir = FEAT_DIR, target_df = TARGET_DF, verbose = True, \n",
    "                  europe_lag = -1, asia_lag = -1, usa_lag = 0):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    -------\n",
    "    asset_name: str\n",
    "        the name of the target asset\n",
    "    \n",
    "    feature_name_list: str\n",
    "        what feature sets we'll be using, each feature name corresponds to a folder name\n",
    "        if feature_name begins with \"self\", then we need to load the feature file with the name of the given asset,\n",
    "        if feature_name begins with \"index\", then load all features in given folde\n",
    "        \n",
    "    feature_dir: str\n",
    "        location of feature data\n",
    "    \n",
    "    verbose: bool\n",
    "        whether to show execution messages\n",
    "        \n",
    "    europe_lag: int\n",
    "        additional lag applied on europe data\n",
    "    \n",
    "    asia_lag: int\n",
    "        additional lag applied on asia data\n",
    "    \n",
    "    usa_lag: int\n",
    "        additional lag applied on usa data\n",
    "    \"\"\"\n",
    "    feat_df_list = []\n",
    "    if verbose:\n",
    "        print(\"******* loading features on {} *******\".format(asset_name))\n",
    "    for feature_name in feature_name_list:\n",
    "        if re.search(\"^self_\", feature_name):\n",
    "            # if the feature name begins with self_, then just load corresponding data file\n",
    "            feat_path = os.path.join(feature_dir, feature_name, \"{}.csv\".format(asset_name))\n",
    "            df = pd.read_csv(feat_path, sep = \";\", header = 0, index_col = 0)\n",
    "            feat_df_list.append(df)\n",
    "        elif re.search(\"^index_\", feature_name):\n",
    "            # if the feature_name begins with index_, use all the features in the folder as features\n",
    "            current_dir = os.path.join(feature_dir,  feature_name)\n",
    "            for fname in os.listdir(current_dir):\n",
    "                feat_path = os.path.join(current_dir, fname)\n",
    "                df = pd.read_csv(feat_path, sep = \";\", header = 0, index_col = 0)\n",
    "                if re.search(\"|\".join(EUR_INDEX), fname) and (europe_lag != 0):\n",
    "                    # europe market data\n",
    "                    df = df.shift(europe_lag)\n",
    "                    df.columns = [\"{}_lag_{}\".format(x, europe_lag) for x in df.columns]\n",
    "                elif re.search(\"|\".join(ASIA_INDEX), fname) and (asia_lag != 0):\n",
    "                    df = df.shift(asia_lag)\n",
    "                    df.columns = [\"{}_lag_{}\".format(x, asia_lag) for x in df.columns]\n",
    "                elif re.search(\"|\".join(USA_INDEX), fname) and (usa_lag != 0):\n",
    "                    df = df.shift(usa_lag)\n",
    "                    df.columns = [\"{}_lag_{}\".format(x, usa_lag) for x in df.columns]\n",
    "                \n",
    "                feat_df_list.append(df)\n",
    "        \n",
    "    feat_df = pd.concat(feat_df_list, axis = 1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"raw feature shape: {}\".format(feat_df.shape))\n",
    "    \n",
    "    feat_df['target'] = target_df[asset_name]\n",
    "    \n",
    "    feat_df, target = format_feat_df(feat_df, verbose)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"cleaned feature shape: {}\".format(feat_df.shape))\n",
    "    \n",
    "    return feat_df, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_split_data(X, y, mode, nb_days = 252):\n",
    "    \"\"\"\n",
    "    split data for validation purpose (or asset selection)\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    mode: str\n",
    "        - \"cv\": classic 5 folds cross validation\n",
    "        - \"test\", classic train test split, using one year of data as test \n",
    "        - \"ts\", time series based 5 folds sequential splitting\n",
    "    nb_days: int\n",
    "        nb of trading days a year\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    out: list\n",
    "        list of 4-tuples (X_train, y_train, X_test, y_test)\n",
    "    \"\"\"\n",
    "    train_test_list = []\n",
    "    \n",
    "    if mode == \"single\":\n",
    "        X_train = X[:nb_days, :]\n",
    "        X_test = X[-nb_days:, :]\n",
    "\n",
    "        y_train = y[:nb_days]\n",
    "        y_test = y[-nb_days:]\n",
    "        \n",
    "        train_test_list.append((X_train, y_train, X_test, y_test))\n",
    "    elif mode == \"cv\":\n",
    "        cv = KFold(n_splits = 5, shuffle = False, random_state = 2017)\n",
    "        for train_index, test_index in cv.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            train_test_list.append((X_train, y_train, X_test, y_test))\n",
    "    elif mode == \"ts\":\n",
    "        ts = TimeSeriesSplit(n_splits = 5)\n",
    "        for train_index, test_index in ts.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            train_test_list.append((X_train, y_train, X_test, y_test))\n",
    "    else:\n",
    "        print(\"split mode undefined: {}\".format(mode))\n",
    "        sys.exit(1)\n",
    "    return train_test_list \n",
    "\n",
    "def main_split_data(X, y, mode, nb_days = 252):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    -------\n",
    "    X: numpy ndarray\n",
    "        training variables\n",
    "    y: array like\n",
    "        target variable\n",
    "    mode: str\n",
    "        \"cv\", \"test\" or \"ts\"\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    out: (4-tuple, list of 4-tuples)\n",
    "        (X_train, y_train, X_test, y_test), list of 4 tuples for validation purpose\n",
    "    \"\"\"\n",
    "    # First split out test set which is the last one year data\n",
    "    X_train = X[:-nb_days, :]\n",
    "    X_test = X[-nb_days:, :]\n",
    "    \n",
    "    # this test set will be used to compare all strategies\n",
    "    y_train = y[:-nb_days]\n",
    "    y_test = y[-nb_days:]\n",
    "    \n",
    "    # split the training set for validation purpose\n",
    "    validation_list = validation_split_data(X = X_train, y = y_train, mode = mode, nb_days = nb_days)\n",
    "    return (X_train, y_train, X_test, y_test), validation_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_on_validation_list(validation_list, clf, out_name, folder_name, out_dir = RES_DIR, verbose = True, to_save = True):\n",
    "    \"\"\"\n",
    "    Run prediction and save result to disk \n",
    "    \n",
    "    Params:\n",
    "    --------\n",
    "    validation_list: list of 4-tuples\n",
    "        (X_train, y_train, X_test, y_test) tuples\n",
    "    clf: predictor\n",
    "        fit and predict\n",
    "    out_name: str\n",
    "        result file name, usaully set to asset name itself\n",
    "    folder_name: str\n",
    "        the method name used as the folder name to save all the prediction results \n",
    "    \n",
    "    \"\"\"\n",
    "    # res_df = pd.DataFrame()\n",
    "    to_dir = os.path.join(out_dir, folder_name)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"**** Running Prediction on {} with {} *****\".format(out_name, folder_name))\n",
    "    \n",
    "    if not os.path.isdir(to_dir):\n",
    "        os.makedirs(to_dir)\n",
    "    \n",
    "    out_path = os.path.join(to_dir, \"{}.csv\".format(out_name))\n",
    "    acc_list, auc_list = [], []\n",
    "    \n",
    "    res_df_list = []\n",
    "    for i, (X_train, y_train, X_test, y_test) in enumerate(validation_list):\n",
    "        res_df = pd.DataFrame()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        res_df[\"true_{}\".format(i)] = y_test\n",
    "        res_df[\"pred_{}\".format(i)] = y_pred\n",
    "        \n",
    "        res_df_list.append(res_df)\n",
    "\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "        \n",
    "        auc_list.append(auc)\n",
    "        acc_list.append(acc)\n",
    "            \n",
    "    res_df = pd.concat(res_df_list, axis = 1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Result on {} - avg AUC: {:0.4f}, avg Accuracy: {:0.4f}\".format(out_name, np.mean(auc_list), np.mean(acc_list)))\n",
    "    \n",
    "    if to_save:\n",
    "        res_df.to_csv(out_path, index = False, header = True, sep = \";\")\n",
    "    \n",
    "    return np.mean(auc_list)\n",
    "\n",
    "def main_predict_all_stocks_on_validation(feature_name_list, \n",
    "                                   validation_mode, \n",
    "                                   clf, \n",
    "                                   clf_name,                                  \n",
    "                                   verbose = True, \n",
    "                                   nn_param_dict = None):\n",
    "    \"\"\"\n",
    "    Run prediction on all assets\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    feature_name_list: list of str\n",
    "        list of feature set to use\n",
    "    \n",
    "    validation_mode: str\n",
    "        \"test\", \"cv\", or \"ts\". It defines which validation scheme to use\n",
    "    \n",
    "    clf: predictor\n",
    "    \n",
    "    clf_name: str\n",
    "        predictor's name\n",
    "    \n",
    "    verbose: bool\n",
    "        whether to show execution messages\n",
    "        \n",
    "    \"\"\"\n",
    "    # method_name identifies the current approach \n",
    "   \n",
    "    method_name = \"-\".join([\"+\".join(feature_name_list), clf_name, validation_mode])\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    # df_raw will be used to extract target variables\n",
    "   \n",
    "    df_raw = TARGET_DF\n",
    "   \n",
    "    # get the name of all assets\n",
    "    asset_list = df_raw.columns\n",
    "    tot = len(asset_list)\n",
    "    for i, asset_name in enumerate(asset_list):\n",
    "        # load feature set\n",
    "        to_path = os.path.join(RES_DIR, method_name, \"{}.csv\".format(asset_name))\n",
    "       \n",
    "        feat_df, target = load_features(\n",
    "                                        asset_name = asset_name, \n",
    "                                        feature_name_list = feature_name_list, \n",
    "                                        feature_dir = FEAT_DIR, \n",
    "                                        target_df = df_raw,\n",
    "                                        verbose = verbose)\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        X = ss.fit_transform(feat_df.values)\n",
    "        y = np.array(list(target))\n",
    "\n",
    "        # split\n",
    "        (X_train, y_train, X_test, y_test), validation_list = main_split_data(X = X, y = y, mode = validation_mode)\n",
    "\n",
    "        # run prediction\n",
    "        predict_on_validation_list(validation_list = validation_list, \n",
    "                                   clf = clf, \n",
    "                                   out_name = asset_name, \n",
    "                                   folder_name = method_name,\n",
    "                                   out_dir = RES_DIR, \n",
    "                                   verbose = False, \n",
    "                                   to_save = True)\n",
    "        if verbose:\n",
    "            print(\"{}/{} Ended\".format(i + 1, tot))\n",
    "    \n",
    "    print(\"Total time spend: {} mins\".format((time.time() - t0)//60))\n",
    "\n",
    "def main_predict_sp500_index_on_validation(feature_name_list, validation_mode, \n",
    "                                     clf, clf_name, to_std = True, \n",
    "                                     verbose = True, \n",
    "                                     nn_param_dict = None, \n",
    "                                     to_save = True):\n",
    "    \"\"\"\n",
    "    We only predict the sp500 index for now\n",
    "    \"\"\"\n",
    "    \n",
    "    asset_name = \"snp\"\n",
    "   \n",
    "    method_name = \"-\".join([\"+\".join(feature_name_list), clf_name, validation_mode])\n",
    "    \n",
    "    df_raw = TARGET_DF_INDEX\n",
    "    \n",
    "    to_path = os.path.join(RES_DIR, method_name, \"{}.csv\".format(asset_name))\n",
    "    \n",
    "   \n",
    "    feat_df, target = load_features(\n",
    "                                    asset_name = asset_name, \n",
    "                                    feature_name_list = feature_name_list, \n",
    "                                    feature_dir = FEAT_DIR, \n",
    "                                    target_df = df_raw,\n",
    "                                    verbose = False)\n",
    "\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    X = ss.fit_transform(feat_df.values)\n",
    "    y = np.array(list(target))\n",
    "\n",
    "    # split\n",
    "    (X_train, y_train, X_test, y_test), validation_list = main_split_data(X = X, y = y, mode = validation_mode)\n",
    "\n",
    "    # run prediction\n",
    "    return predict_on_validation_list(validation_list = validation_list, \n",
    "                               clf = clf, \n",
    "                               out_name = asset_name, \n",
    "                               folder_name = method_name,\n",
    "                               out_dir = RES_DIR, \n",
    "                               verbose = False, \n",
    "                               to_save = to_save)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_best = LogisticRegression(penalty = \"l1\", C = 0.05)\n",
    "main_predict_all_stocks_on_validation(feature_name_list = [\"self_lag_5\", \"index_lag_5\"], \n",
    "                               validation_mode = \"ts\", \n",
    "                               clf = lr_best, \n",
    "                               clf_name = \"logistic-regression\", \n",
    "                               verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_auc_list_from_dir(folder_name, result_dir = RES_DIR):\n",
    "    from_dir = os.path.join(result_dir, folder_name)\n",
    "    auc_list = []\n",
    "    for filename in os.listdir(from_dir):\n",
    "        df = pd.read_csv(os.path.join(from_dir, filename), sep = \";\", header = 0, index_col = None)\n",
    "        nb = int(df.shape[1]/2)\n",
    "        tmp_auc_list = []\n",
    "        for i in range(nb):\n",
    "            y_pred = df['pred_{}'.format(i)].values\n",
    "            y_test = df['true_{}'.format(i)].values\n",
    "            auc = roc_auc_score(y_test, y_pred)\n",
    "            tmp_auc_list.append(auc)\n",
    "        auc = np.mean(tmp_auc_list)\n",
    "        auc_list.append(auc)\n",
    "    return auc_list  \n",
    "\n",
    "def show_overall_performance(folder_name, result_dir = RES_DIR, show_hist = False):\n",
    "    from_dir = os.path.join(result_dir, folder_name)\n",
    "    acc_list = []\n",
    "    auc_list = []\n",
    "    for filename in os.listdir(from_dir):\n",
    "        df = pd.read_csv(os.path.join(from_dir, filename), sep = \";\", header = 0, index_col = None)\n",
    "        nb = int(df.shape[1]/2)\n",
    "        tmp_auc_list = []\n",
    "        tmp_acc_list = []\n",
    "        for i in range(nb):\n",
    "            y_pred = df['pred_{}'.format(i)].values\n",
    "            y_test = df['true_{}'.format(i)].values\n",
    "            auc = roc_auc_score(y_test, y_pred)\n",
    "            tmp_auc_list.append(auc)\n",
    "            acc = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "            tmp_acc_list.append(acc)\n",
    "        \n",
    "        auc_list.append(np.mean(tmp_auc_list))\n",
    "        acc_list.append(np.mean(tmp_acc_list))\n",
    "    \n",
    "    print(\"Result on {} - avg AUC: {:0.4f} with std: {:0.4f}, avg Accuracy: {:0.4f} with std: {:0.4f}\".\\\n",
    "          format(folder_name, np.mean(auc_list), np.std(auc_list), np.mean(acc_list), np.std(acc_list))) \n",
    "    if show_hist:\n",
    "        plt.hist(auc_list, bins = 30, alpha=0.5, label=\"AUC\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "    \n",
    "    return np.mean(auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_overall_performance(folder_name = \"self_lag_5+index_lag_5-logistic-regression-ts\", show_hist = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
